---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data: Live Session 7 - Time Series Lecture 2'
author: "Professor Jeffrey Yau"
output:
  pdf_document: default
---

#Main Topics Covered in Lecture 7:

    - Time Series Libraries in R
    - Exploratory time-series data analysis
    - Classical Linear Regression Model (CLM) for time series data
    - Linear time-trend regression
    - Time-series smoothing techniques
    
#Required Readings:

**CM2009:** Paul S.P. Cowpertwait and Andrew V. Metcalfe. *Introductory Time Series with R*. Springer. 2009. 

    - Ch. 5.1 – 5.3

# Start-up Code

```{r, message=FALSE, warning=FALSE}
# Insert the function to *tidy up* the code when they are printed out
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

# Load required libraries
library(car)
library(dplyr)
library(readr)
library(astsa)
library(xts)
library(forecast)
library(ggplot2)
library(plotly)
library(tsibble)
library(fable)
library(fpp2)
library(fpp3)

# if required for fable installation: https://cran.r-project.org/bin/macosx/tools/
```  

# tidyquant package

Retrieve the same Federal Reserve Economic Database series, *4-Week Moving Average of Initial Claims* (IC4WSA), as used in the previous Live Session file.

```{r}

library(tidyquant)
#https://cran.r-project.org/web/packages/tidyquant/vignettes/TQ00-introduction-to-tidyquant.html

init_claims <- tq_get('IC4WSA', 
                      get = "economic.data", 
                      from = "1967-01-01") %>% 
  rename(claims = price) %>% 
  mutate(claims = claims/1000) %>% 
  as_tsibble()

str(init_claims)
head(init_claims)
tail(init_claims)

init_claims %>% 
  ggplot(aes(x = date, y = claims)) +
  geom_line(colour = "maroon", size = 1) +
  ggtitle('Initial Unemployment Claims') +
  theme(legend.position = "none")
```

```{r}
claims_2010s <- init_claims %>% filter_index('2010'~'2020.') 

head(claims_2010s)
head(claims_2010s)

claims_2010s %>% 
  ggplot(aes(x = date, y = claims)) +
  geom_line(colour = "maroon", size = 1) +
  ggtitle('Initial Unemployment Claims') +
  theme(legend.position = "none")
```


# Deterministic Linear Time Trend Model

**In a break-out room, do the following exercises:**

  1. Estimate a deterministic linear time trend model using the `claims_2010s` data
  
  2. Print the summary estimation results
  
  3. Plot a time series plot of the original series and the estimated linear time trend

```{r}
claims_2010s <- claims_2010s %>% mutate(time_index = row_number())

# YOUR CODE HERE
linear.trend.fit <- lm(claims ~ time_index, data=claims_2010s)

linear.trend.fit
```


## Quadratic Time Trend Model

**Repeat the above exercises but for a quadratic time trend model**


```{r}
# YOUR CODE HERE
quadratic.trend.fit <- lm(claims ~ time_index + I(time_index^2), data=claims_2010s)
```

## Exponential Time Trend Model

**Repeat the above exercises but for an exponential time trend model**

$$
log(y_t) = \beta_0 + \beta_1 t + \epsilon_t \\ 
y_t = e^{\beta_0 + \beta_1 t + \epsilon_t}
$$


```{r}
# YOUR CODE HERE 
exp.trend.fit <- lm(log(claims) ~ time_index, data=claims_2010s)
```

## Regression Diagnostic Results

**Discuss the following regression diagnostic results. Feel free to modify the code to facilitate your discussion.**

```{r}
library(car)
model_diagnostic = function(model) {
  plot(model)
  
  residualPlots(model)  
}

model_diagnostic(linear.trend.fit)
model_diagnostic(quadratic.trend.fit)
model_diagnostic(exp.trend.fit)
```

### Recap of AIC and BIC

**Akaike Information Criterion (AIC)**

$AIC = -2 \times logL_k + 2 \times k$
where $logL_k$ is the maximized log-likelihood and $k$ is the number of parameters in the model.

One could normalize it by $n$, the number of observation used to estimate the model, and obtain

$$
  AIC = \frac{-2logL_k + 2k}{n} \approx ln(\hat{\sigma}^2) + \frac{2k}{n} + c
$$

where $\hat{\sigma}^2$ denotes the MLE of $\sigma^2$ and $c$ is some constant.

**Bayesian Information Criteria (BIC)**

This allows one to compare with another commonly used information criteria, *Bayesian Information Criteria*:

$$
  BIC = ln(\hat{\sigma}^2) + k\frac{ln(n)}{n}
$$

  * Note that BIC imposes a greater penalty for the number of estimated model parameters than does AIC. As such, BIC would always gives a model whose number of parameters is no greater than that chosen under AIC.

  * Information criteriion model selection process should NOT be use as a substitute for careful examination of characteristics of the estimated autocorrelation and partial autocorrelation; it can be used as a supplemenatry guidelines.

  * Critial examination of the residual series for model inadequacies should always be included as a major aspect of the overall model selection process.


```{r}
cbind(AIC(linear.trend.fit, quadratic.trend.fit, exp.trend.fit),
      BIC(linear.trend.fit, quadratic.trend.fit, exp.trend.fit))
```

Compare sums of squared residuals

```{r}
deviance(linear.trend.fit)
deviance(quadratic.trend.fit)
deviance(exp.trend.fit)

# the exponential model is in log space, so to be made comparable
sum(claims_2010s$claims - exp(exp.trend.fit$fitted.values))^2
```

Test for autocorrelation of residuals

```{r}
durbinWatsonTest(linear.trend.fit)
durbinWatsonTest(quadratic.trend.fit)
durbinWatsonTest(exp.trend.fit)
```

## Forecasts of Linear Time Trends

**Discuss the following forecasting procedure. Feel free to modify the code to facilitate your discussion.**

```{r}
predict.data = data.frame(x = seq(459, 510, 1), x2 = seq(459, 510, 1)^2)

linear.predict = linear.trend.fit$coefficients[1] + linear.trend.fit$coefficients[2]*predict.data$x 

quadratic.predict = quadratic.trend.fit$coefficients[1] + quadratic.trend.fit$coefficients[2]*predict.data$x + 
quadratic.trend.fit$coefficients[3]*predict.data$x2

exp.predict = exp(exp.trend.fit$coefficients[1] + exp.trend.fit$coefficients[2]*predict.data$x)

dump = data.frame(predict.data[1], 
                  linear.predict, quadratic.predict, exp.predict)

ggplot(data = dump, aes(x=seq(52), y=value, colour=variable)) +
  ylab('Values') +
  geom_line(aes(y=linear.predict, col = "linear forecast")) +
  geom_line(aes(y=quadratic.predict, col = "quadratic forecast")) +
  geom_line(aes(y=exp.predict, col = "exponential forecast")) +
  ggtitle("Initial Unemployment Claims") +
  theme(title = element_text(size = rel(1.25)),
        legend.position = "bottom")

```

Forecasts with Fable

```{r}
# YOUR CODE HERE 

linear.trend.forecast <- claims_2010s %>% model(TSLM(claims ~ trend())) %>% forecast(h = 100) 
quadratic.trend.forecast <- claims_2010s %>% model(TSLM(claims ~ trend() + I(trend()^2))) %>% forecast(h = 100) 
exp.trend.forecast <- claims_2010s %>% model(TSLM(log(claims) ~ trend())) %>% forecast(h = 100)

claims_2010s %>% autoplot(claims) + autolayer(rbind(linear.trend.forecast, quadratic.trend.forecast, exp.trend.forecast))
```

# Modeling and Forecasting Seasonality

Seasonality arises from links of technologies, preferences, and institutions to the calendar.

A key technique for modeling seasonality is regression on seasonal dummy variables.

$$
  y_t = \sum_{i=1}^s \gamma_i D_{it} + \epsilon_t
$$

Incorporating holidays:

$$
  y_t = \sum_{i=1}^s \gamma_i D_{it} + \sum_{i=1}^v \gamma_i^{HD} HDV_{it}  + \epsilon_t
$$
where $HDV_{it}$ denotes relevant holiday variables, and there are $v$ of them.

Incorporating both Trend and Seasonality in a model:

$$
  y_t = \beta_1 TIME_t + \sum_{i=1}^s \gamma_i D_{it} + \epsilon_t
$$


## Example

```{r}
recent_production <- aus_production %>%
  dplyr::filter(year(Quarter) >= 1992)

str(recent_production)
head(recent_production)
tail(recent_production)

recent_production %>%
  autoplot(Beer) +
  labs(x = "Year", y = "Megalitres")

recent_production %>% gg_season(Beer, year.labels=TRUE, year.labels.left=TRUE) +
  ylab("Megalitres") +
  ggtitle("Seasonal plot: Beer production")

recent_production %>% gg_subseries(Beer) +
  ylab("Megalitres") +
  ggtitle("Seasonal subseries plot: Beer production")
```


We want to forecast the value of future beer production. We can model this data using a regression model with a linear trend and quarterly dummy variables

```{r}
fit_beer <- recent_production %>%
  model(TSLM(Beer ~ trend() + season()))
report(fit_beer)
```

Note that `trend` and `season` are not objects in the R workspace; they are created automatically by `TSLM()` when specified in this way.

```{r}
augment(fit_beer) %>%
  ggplot(aes(x = Quarter)) +
  geom_line(aes(y = Beer, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(x = "Year", y = "Megalitres",
       title = "Quarterly Beer Production")
```

```{r}
augment(fit_beer) %>%
  ggplot(aes(x = Beer, y = .fitted,
             colour = factor(quarter(Quarter)))) +
    geom_point() +
    ylab("Fitted") + xlab("Actual values") +
    ggtitle("Quarterly beer production") +
    scale_colour_brewer(palette="Dark2", name="Quarter") +
    geom_abline(intercept=0, slope=1)
```

```{r}
recent_production <- aus_production %>% filter(year(Quarter) >= 1992)
fit_beer <- recent_production %>%
  model(TSLM(Beer ~ trend() + season()))
fc_beer <- forecast(fit_beer)
fc_beer %>%
  autoplot(recent_production) +
  ggtitle("Forecasts of beer production using regression") +
  xlab("Year") + ylab("megalitres")
```

## Harmonic Regression

A Fourier series is a periodic function composed of series of sine and cosine terms of varying frequencies. Fourier terms can be incorporated into a time series regression to model seasonal patterns. This type of model element is sometimes known as 'trigonometric seasonality'.

If $m$ is the seasonal period, then the first few terms of a Fourier series are given by 
$x_{1,t}=\sin(2\pi t m)$,
$x_{2,t}=\cos(2\pi t m)$,
$x_{3,t}=\sin(4\pi t m)$,
$x_{4,t}=\cos(4\pi t m)$,
$x_{5,t}=\sin(6\pi t m)$,
$x_{5,t}=\cos(6\pi t m)$

and so on. 

If we have monthly seasonality, and we use the first 11 of these predictor variables, then we will get exactly the same forecasts as using 11 dummy variables.

With Fourier terms, we often need fewer predictors than with dummy variables, especially when $m$ is large. This makes them useful for weekly data, for example, where $m \approx 52$ (for short seasonal periods (e.g., quarterly data), there is little advantage in using Fourier terms over seasonal dummy variables).

These Fourier terms are produced using the `fourier(x, K)` function in R, where `x` is a seasonal time series and `K` is the order of Fourier terms, up to a maximum of $K=m/2$. A regression model containing Fourier terms can be called a harmonic regression.  

For example, Australian beer production data can be modelled like this:

```{r message=FALSE}
recent_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
fourier_beer <- recent_production %>%
  model(TSLM(Beer ~ trend() + fourier(K=2)))
report(fourier_beer)
fc_beer <- forecast(fourier_beer)
fc_beer %>%
  autoplot(recent_production) +
  ggtitle("Forecasts of beer production using harmonic regression") +
  xlab("Year") + ylab("megalitres")
```

**Exercise**

The `us_gasoline` series from the `fpp3` package consists of weekly data for supplies of US finished motor gasoline product, from 2 February 1991 to 20 January 2017. The units are in “million barrels per day”. Consider only the data to the end of 2004.

Fit a harmonic regression with trend to the data. Select the appropriate number of Fourier terms to include by minimising the AIC value. Plot and describe the observed and fitted gasoline values.

```{r}
us_gasoline %>% autoplot() + ggtitle("US Finished Motor Gasoline Supplied") +
  xlab("Week") + ylab("Million barrels per day")
```

Scan up to m/2 = 26 for K, the order of Fourier terms. 

```{r}
gas.fit <- us_gasoline %>% filter(year(Week) <= 2004)

#generate matrix to store values
aic.scan <- matrix(nrow = 26, ncol = 2)

for (K in seq(1,26)) {
  fourier_gas <- gas.fit %>%
    model(TSLM(Barrels ~ trend() + fourier(K=K))) %>% glance()
  aic.scan[K, 1] <- K
  aic.scan[K, 2] <- fourier_gas$AIC
}
aic.scan <- data.frame(aic.scan)
colnames(aic.scan) <- c('K', 'AIC')

#Get the top 5 values
aic.scan[order(aic.scan$AIC),] %>% head(5)
```

The best AIC occurs at f=7

```{r}
fourier_gas <- gas.fit %>%
  model(TSLM(Barrels ~ trend() + fourier(K=7)))
fourier_gas %>% glance()

fitted.plot <- augment(fourier_gas) 
colnames(fitted.plot) <- c(".model", "Week", "Actual", "Fitted", ".resid")
fitted.plot <- fitted.plot %>% gather(actual_vs_fitted, value, -.model, -Week, -.resid)

ggplot(data = fitted.plot, aes(x = Week, y = value, color = actual_vs_fitted)) + 
  geom_line(alpha = 1) + 
  labs(x = 'Date', y = 'Gasoline',
       title = 'Harmonic Regression of Supply of US Gasoline') + 
  theme_minimal()

gg_tsresiduals(fourier_gas, lag_max = 104)
```
Test the model forecast on 2005 data

```{r}
test.gas <- us_gasoline %>% dplyr::filter(year(Week) == 2005)
fc.gas <- fourier_gas %>% forecast(test.gas)
fc.gas %>% autoplot() +
  geom_line(data = test.gas, aes(x = Week, y = Barrels, color = 'Actual')) + 
  labs(title = 'Harmonic forecast versus actual US Gas suppies',
       level = 'Forecast CI',
       colour = 'Data') 
```
