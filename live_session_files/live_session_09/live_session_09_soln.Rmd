---
title: 'W271 Live Session 9: ARIMA and SARIMA'
author: "MIDS W271"
output:
  pdf_document: default
---

# Main topics covered in Week 9
  - Mixed Autoregressive Moving Average (ARMA) Models
    - Mathematical formulation and derivation of key properties
    - Comparing ARMA models and AR models using simulated series
    - Comparing ARMA models and AR models using an example
 
  - An introduction to non-stationary time series model

  - Random walk and integrated processes

  - Autoregressive Integrated Moving Average (ARIMA) Models
    - Discuss the steps to build ARIMA time series model: Box-Jenkins' approach
    - Simulation
    - Modeling with simulated data using the Box-Jenkins approach
    - Estimation, model diagnostics, model identification, model selection, assumption testing, and statistical inference / forecasting, backtesting

  - Seasonal ARIMA (SARIMA) Models
    - Mathematical formulation
    - An empirical example

  - Putting everything together: ARIMA modeling

# Readings
**CM2009:** Paul S.P. Cowpertwait and Andrew V. Metcalfe. *Introductory Time Series with R*. Springer. 2009. 
  
  - Ch. 4.3 – 4.7, 6, 7.1 – 7.3

**HA:** Rob J Hyndman and George Athanasopoulos. Forecasting: Principles and Practice: 
  - Ch. 9.5 – 9.9


# Recap and overview

1. Last week, we were introduced to autoregressive (AR), moving average (MA), and autoregressive moving average (ARMA) models. These models are only appropriate for time-series that are weakly stationary (stationary in the mean and the variance).

2. We are often confronted with time-series that are not stationary in the mean and variance (and other forms, such as seasonality and volatility clustering). Luckily, many of the non-stationary series can be simply transformed into stationary series using very simple transformation such as differencing.

3. Here are some common reasons why time-series might not be stationary in the mean:

    a. The series has a trend
    b. The series contains seasonal elements
    c. The series contains time-varying variance
    
4. We can take care of some of these problems either by de-trending the data or by differencing the data. In fact, we did this in our two lectures on time series analysis; we modeled the trend and seasonality directly. In the context of ARIMA modeling, we would apply transformation to "attempt" to convert a non-stationary series into a stationary series. Once the data are transformed into a weakly stationary series, we can model the resulting series with an ARMA model. We call these models ARIMA models if the data do not exhibit any seasonality. If the data are seasonal, then these models are called SARIMA models - an ARIMA model with seasonal components.

5. Remember, here are the steps to building an ARIMA model (assuming that you already have your questions well-defined and data collected and cleansed):

    i. Conduct an EDA to determine if you need to transform the series in order to make it stationary.
    ii. Transform the series if needed.
    iii. Estimate several `ARIMA(p,d,q)x(P,D,Q)s` models, with starting values coming from the examination of time series plot, ACF, and PACF.
    iv. Evaluate the residuals of models that have the lowest AIC and/or BIC values and models that are more parsimonious. Select the model where the residuals resemble white nose.
    v. Answer your question / generate forecasts!
    

# EDA, Data transformation, and Discussion
We are going to practice ARIMA modeling with the possibility of using seasonal components if the series warrants it. For the practice, we will use the "relative search activity for the phrase `flight prices`". This series, contained in a data set with many other variables, is provided by google correlate, and they come in a weekly frequency. For simplicity, we will focus on the series from the year 2010 onward.

Remember that we can express a SARIMA model as: $ARIMA(p,d,q)\times(P,D,Q)_m$.

The following code loads a dataset, selects one specific series, converts it to a time-series object, and splits the data into training and test sets.

```{r}
# Insert the function to *tidy up* the code when they are printed out
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

# Load libraries
library(forecast)
library(lubridate)
library(fable)
library(fpp2)
library(fpp3)
library(astsa)
library(dplyr)
library(Hmisc)
```


**Breakout room sessions**
  - Load the file
  - Examine the data
  - Subset the data frame to include only the flight.prices series
  - Create a R time-series object
  - Keep data between 2010 and 2014. Leave 2015 data as a hold-out or  test data which we will use later
  - Conduct EDA
  

```{r}
df <- read.csv("correlate-flight_prices.csv", header = TRUE, sep=",")

glimpse(df)
```

```{r}
# Create an R time-series object
df <- read.csv("correlate-flight_prices.csv", header = TRUE, sep=",")
fp <- ts(df$flight.prices, frequency = 52.1429, start = c(2004,1))
fp.training <- fp[time(fp) >= 2010 & time(fp) < 2015]
fp.training <- ts(fp.training, frequency = 52, start = c(2010,1))

str(fp)
head(fp)

hist(fp.training)
acf(fp.training, lag.max = 100)
pacf(fp.training, lag.max = 100)
```

The series displays seasonality and downward trend within each season.

  - The ```monthplot()``` function plots "aggregated" series of an entire time series. 
  - For each season, a time series is plotted. 
  - Data for each season is collected together in time plot as separate time series
  - All of the series are plotted in the same graph
  - This may expose the underlying seasonal pattern and allow the changes in seasonality over time to be visualized

```{r}
monthplot(fp.training)
boxplot(fp.training ~ cycle(fp.training))
```

Alternatively, using dplyr and constructing a tsibble 


```{r}
# Alternatively, using dplyr
correlate.prices <- df %>% 
  gather(term, freq, -Date) %>% 
  mutate(Date = mdy(Date)) %>% 
  as_tsibble(index = Date, key = term)

flight.prices <- correlate.prices %>% 
  filter(term == 'flight.prices') 

flight.prices.training <-  flight.prices %>% filter_index('2010'~'2014') 
flight.prices.test <- flight.prices %>% filter_index('2015'~.)


autoplot(flight.prices.training, freq) + 
  autolayer(flight.prices.test, freq, colour = 'red')
```


Next, let's examine some differencing-transformation of the series:
  - seasonal differencing
  - non-seasonal differencing
  - non-seasonal differencing on top of seasonal differencing


```{r}
fp.training %>%
  ggtsdisplay()
```
```{r}
fp.training %>% diff() %>% 
  ggtsdisplay()
```
```{r}
fp.training %>% diff(52) %>% 
  ggtsdisplay()
```
```{r}
fp.training %>% diff(52) %>% diff() %>% 
  ggtsdisplay()
```


# Modeling the non-seasonal component
First, let's model the non-seasonal component of the raw series. In order to do that, we are going to use the ```ARIMA()``` function of the fable package (equivalent to ```Arima()``` in the forecast package). 

> Professors Hyndman and Athanasopoulos points out that arima() in R can also be used to estimate an ARIMA model, but it does not allow for the constant c unless d=0, does not return everything required for the forecast() function, and does not allow the estimated model to be applied to new data (which is useful for checking forecast accuracy). As such, they recommend using Arima() instead. 


```{r}
# Let's start by modeling it as a pure AR or MA model
print('AR')
for (p in 0:6){
  mod <- flight.prices.training %>% model(ARIMA(freq ~ pdq(p,0,0) + PDQ(0,0,0))) 
  print(paste(p, select(glance(mod), AIC)))
}
print('MA')
for (q in 0:6){
  mod <- flight.prices.training %>% model(ARIMA(freq ~ pdq(0,0,q) + PDQ(0,0,0))) 
  print(paste(q, select(glance(mod), AIC)))
}
```



```{r}
# ARMA models with d = 0

# AIC not comparable between models with different values of d
# comparison across those models would require a different metric (e.g. accuracy() measures, variance of residuals, pseudo-out-of-sample performance)

# We include a ~0 or ~1 in the ARIMA function to exclude or include a constant term (included by default in the forecast package's ```Arima()``` function)

print('ARIMA(p,0,q)')

for (p in 0:3){
  for (q in 0:3){
  mod <- flight.prices.training %>% model(ARIMA(freq ~ 0 + pdq(p,0,q) + PDQ(0,0,0))) 
  print(paste(p, q, select(glance(mod), AIC)))
  }}

```


# Breakout Session: Modeling the seasonal component
In your group, try to find appropriate values for p, d, q, P, D, and Q.


```{r}
# Let's look at some Seasonal ARIMA models

# Include a try catch expression in the loop in case model has unstable characteristic roots

# In this case, SARIMA will not converge in the absence of a constant term


print('ARIMA(1,0,1)(P,0,Q)')

for (P in 1:2){
  for (Q in 1:2){
    tryCatch(
          {mod <- flight.prices.training %>% model(ARIMA(freq ~ 1 + pdq(1,0,0) + 
                                                           PDQ(P,0,Q, 52, approximation = TRUE))) 
           print(paste(P, Q, select(glance(mod), AIC)))
           },
          error = function(e){})
  }}

```

```{r}
# model propertoes
mod <-  flight.prices.training %>% model(arima = ARIMA(freq ~ 1 + pdq(1,0,1) + 
                                                           PDQ(2,0,2, period = 52))) 
mod %>% report()

# residual characteristics
mod %>% gg_tsresiduals()

# test for autocorrelaton of residuals
augment(mod) %>% features(.resid, ljung_box)

```

